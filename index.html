<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
  <head>
  <meta name=viewport content=“width=800”>
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
    /* Color scheme stolen from Sergey Karayev */
    a {
    color: #1772d0;
    text-decoration:none;
    }
    a:focus, a:hover {
    color: #f09228;
    text-decoration:none;
    }
    body,td,th,tr,p,a {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px
    }
    strong {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px;
    }
    heading {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 22px;
    }
    papertitle {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px;
    font-weight: 700
    }
    name {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 32px;
    }
    .one
    {
    width: 160px;
    height: 160px;
    position: relative;
    }
    .two
    {
    width: 160px;
    height: 160px;
    position: absolute;
    transition: opacity .2s ease-in-out;
    -moz-transition: opacity .2s ease-in-out;
    -webkit-transition: opacity .2s ease-in-out;
    }
    .fade {
     transition: opacity .2s ease-in-out;
     -moz-transition: opacity .2s ease-in-out;
     -webkit-transition: opacity .2s ease-in-out;
    }
    span.highlight {
        background-color: #ffffd0;
    }
  </style>
  <link rel="icon" type="image/png" href="seal_icon.png">
  <title>Yeming Wen</title>
  <meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
  <link href='http://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
  </head>
  <body>
  <table width="800" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
    <td>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td width="67%" valign="middle">
        <p align="center">
          <name>Yeming Wen</name>
        </p>
        <p>I am a computer science graduate student at UT Austin, advised by <a href="https://www.cs.utexas.edu/~swarat/">Prof. Swarat Chaudhuri</a>. My research focuses on building a machine learning framework to generate code with human-like efficiency. Before joining UT Austin, I was a master student in computer science advised by <a href="https://jimmylba.github.io/"> Prof. Jimmy Ba</a> at University of Toronto. I worked on the development of efficient learning algorithms for deep neural networks.

        <p align=center>
          <a href="mailto:ywen@cs.toronto.edu">Email</a> &nbsp/&nbsp
          <a href="ywen_cv.pdf">CV</a> &nbsp/&nbsp
          <a href="https://scholar.google.ca/citations?user=J2GzNAkAAAAJ&hl=en">Scholar</a> &nbsp/&nbsp
          <a href="https://www.linkedin.com/in/yeming-wen-0480a6a2/"> LinkedIn </a>
        </p>
        </td>
        <td width="33%">
        <img src="ywen.jpg">
        </td>
      </tr>
      </table>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td width="100%" valign="middle">
          <heading>Publication</heading>
        </td>
      </tr>
      </table>

  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">

    <tr>
      <td width="25%">
        <div class="one">
        <div class="two" id = 'aperture_image'><img src='uncertainty_baselines.jpg' width="270px" height="185px"></div>
        <!-- <img src='LSTM_Variance_Crop.png'> -->
        </div>
      </td>
      <td valign="top" width="50%">
    <a href="https://arxiv.org/pdf/2106.04015.pdf">
            <papertitle>Uncertainty Baselines: Benchmarks for Uncertainty & Robustness in Deep Learning</papertitle>
    </a>
    <br>
    Zachary Nado, Neil Band, Mark Collier, Josip Djolonga, Michael W. Dusenberry, Sebastian Farquhar, Angelos Filos, Marton Havasi, Rodolphe Jenatton, Ghassen Jerfel, Jeremiah Liu, Zelda Mariet, Jeremy Nixon, Shreyas Padhy, Jie Ren, Tim G. J. Rudner, <strong>Yeming Wen</strong>, Florian Wenzel, Kevin Murphy, D. Sculley, Balaji Lakshminarayanan, Jasper Snoek, Yarin Gal, Dustin Tran
        <p>High-quality implementations of standard and SOTA methods on a variety of tasks. Preprints (2021)</p>
      </td>
    </tr>

    <tr>
      <td width="25%">
        <div class="one">
        <div class="two" id = 'aperture_image'><img src='camixup.jpg' width="270px" height="185px"></div>
        <!-- <img src='LSTM_Variance_Crop.png'> -->
        </div>
      </td>
      <td valign="top" width="50%">
    <a href="https://arxiv.org/pdf/2010.09875.pdf">
            <papertitle>Combining Ensembles and Data Augmentation can Harm your Calibration</papertitle>
    </a>
    <br>
    <strong>Yeming Wen*</strong>, Ghassen Jerfel*, Rafael Muller, Michael W. Dusenberry, Jasper Snoek, Balaji Lakshminarayanan & Dustin Tran
    <br>
        <em>International Conference on Learning Representations (ICLR)</em>, 2021 <br>
        <p>By adjusting data augmentation according to calibration, we can exploit both marginalization and invariances.</p>
      </td>
    </tr>

    <tr>
      <td width="25%">
        <div class="one">
        <div class="two" id = 'aperture_image'><img src='rank1.jpg' width="270px" height="185px"></div>
        <!-- <img src='LSTM_Variance_Crop.png'> -->
        </div>
      </td>
      <td valign="top" width="50%">
    <a href="https://arxiv.org/pdf/2005.07186.pdf">
            <papertitle>Efficient and Scalable Bayesian Neural Nets with Rank-1 Factors </papertitle>
    </a>
    <br>
    Michael W. Dusenberry*, Ghassen Jerfel*, <strong>Yeming Wen</strong>, Yi-An Ma, Jasper Snoek, Katherine Heller, Balaji Lakshminarayanan & Dustin Tran 
    <br>
        <em>International Conference on Machine Learning (ICML) </em>, 2020 <br>
        <p>Improved BatchEnsemble with mixture posteriors, Cauchy priors and rank-1 parameterization.</p>
      </td>
    </tr>

    <tr>
      <td width="25%">
        <div class="one">
        <div class="two" id = 'aperture_image'><img src='cost.jpg' width="270px" height="185px"></div>
        <!-- <img src='LSTM_Variance_Crop.png'> -->
        </div>
      </td>
      <td valign="top" width="50%">
    <a href="https://openreview.net/forum?id=Sklf1yrYDr">
            <papertitle>BatchEnsemble: an Alternative Approach to Efficient Ensemble and Lifelong Learning</papertitle>
    </a>
    <br>
          <strong>Yeming Wen</strong>,
    <a href="http://dustintran.com/">Dustin Tran</a> &
    <a href="https://jimmylba.github.io/">Jimmy Ba</a>
    <br>
        <em>8th International Conference on Learning Representations (ICLR)</em>, 2020
    <br>
        <em>Bayesian Deep Learning Workshop at NeurIps</em>, 2019 <br>
        <p>How to efficiently ensemble deep neural networks efficiently in both computation and memory.</p>
      </td>
    </tr>

    <tr>
    <td width="30%" valign="top" align="center">
        <img src="mbbl_front_index.png" alt="" width="100%" style="border-style: none">
        <td width="50%" valign="top">
            <a href="https://arxiv.org/abs/1907.02057">
              <papertitle>Benchmarking Model-Based Reinforcement Learning</papertitle>
            </a>
            <br>
            <a href='http://www.cs.toronto.edu/~tingwuwang/'>Tingwu Wang</a>,
            <a href='https://ca.linkedin.com/in/xuchan-bao-328b8810a'>Xuchan Bao</a>,
            <a href='https://iclavera.github.io/'>Ignasi Clavera</a>,
            <a href='https://www.linkedin.com/in/jerrick-hoang-06093035/'>Jerrick Hoang</a>,
            <strong>Yeming Wen</strong>,
            <a href='https://www.linkedin.com/in/edtsft/?originalSubdomain=ca'>Eric Langlois</a>,
            <a href='https://www.linkedin.com/in/matthew-zhang-218253140/?originalSubdomain=ca'>Shunshi Zhang</a>,
            <a href='http://www.cs.toronto.edu/~gdzhang/'>Guodong Zhang</a>,
            <a href='https://people.eecs.berkeley.edu/~pabbeel/'>Pieter Abbeel</a> &
            <a href='http://jimmylba.github.io/'>Jimmy Ba</a><br>
            <em>Arxiv</em>, 2019<br>

            <p>Benchmarking several commonly used model-based algorithms.</p>
      </td>

    <tr>
      <td width="25%">
        <div class="one">
        <div class="two" id = 'aperture_image'><img src='interplay_fig1.png' width="240px" height="180px"></div>
        <!-- <img src='LSTM_Variance_Crop.png'> -->
        </div>
      </td>
      <td valign="top" width="50%">
    <a href="https://arxiv.org/pdf/1902.08234.pdf">
            <papertitle>An Empirical Study of Large-Batch Stochastic Gradient Descent with Structured Covariance Noise
            </papertitle>
    </a>
    <br>
          <strong>Yeming Wen*</strong>,
    <a>Kevin Luk*</a>,
    <a>Maxime Gazeau*</a>,
    <a href="http://www.cs.toronto.edu/~gdzhang/">Guodong Zhang</a>,
    <a href="https://takonan.github.io/">Harris Chan</a> &
    <a href="https://jimmylba.github.io/">Jimmy Ba</a>
    <br>
        <em>The 23rd International Conference on Artificial Intelligence and Statistics (AISTATS) </em>, 2020 <br>
        <p>How to add a noise to gradients with correct covariance structure such that large-batch training genenalizes better without longer training.</p>
      </td>
    </tr>

    <tr>
      <td width="25%">
        <div class="one">
        <div class="two" id = 'aperture_image'><img src='FlipoutDiagram.jpeg' width="240px" height="200px"></div>
        <!-- <img src='LSTM_Variance_Crop.png'> -->
        </div>
      </td>
      <td valign="top" width="50%">
	  <a href="https://arxiv.org/abs/1803.04386">
            <papertitle>Flipout: Efficient Pseudo-Independent Weight Perturbations on Mini-Batches</papertitle>
	  </a>
	  <br>
          <strong>Yeming Wen</strong>,
	  <a href="https://www.paulvicol.com//">Paul Vicol</a>,
	  <a href="https://jimmylba.github.io/">Jimmy Ba</a>,
	  <a href="http://dustintran.com/">Dustin Tran</a> &
	  <a href="http://www.cs.toronto.edu/~rgrosse/">Roger Grosse</a>
	  <br>
        <em>6th International Conference on Learning Representations (ICLR)</em>, 2018 <br>
        <p>How to efficiently make psedo-independent weight perturbations on mini-batches in evolution strategies and variational BNNs as activation perturbations in dropout.</p>
      </td>
    </tr>


    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr>
            <td><p align="right"><font size="2">
                    <br>Last Update: June, 16th, 2018;<br>

                    Template: <a href='http://people.eecs.berkeley.edu/~pathak/'>this/that</a>,
                    <a href="http://www.cs.berkeley.edu/~barron/">ce/cette</a>,
                    <a href="http://www.cs.berkeley.edu/~akar/">das/der</a>,
                    <a href="http://www.cs.berkeley.edu/~sgupta/">kono/sono</a> and
                    <a href="http://jeffdonahue.com/">zhege/nage</a>.
                </font></p>
            </td>
        </tr>
    </table>
  </body>
</html>
